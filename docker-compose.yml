version: "3.9"

services:
  ollama:
    image: ollama/ollama:latest
    container_name: big_local_ollama
    volumes:
      - ollama:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -sSf http://127.0.0.1:11434/api/tags > /dev/null"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 30s

  web:
    build: .
    container_name: big_local_web
    env_file:
      - .env
    environment:
      # Pass through envs to Flask/app
      - FLASK_RUN_HOST=${APP_HOST:-0.0.0.0}
      - FLASK_RUN_PORT=${APP_PORT:-5000}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - VIDEO_WIDTH=${VIDEO_WIDTH:-1080}
      - VIDEO_HEIGHT=${VIDEO_HEIGHT:-1920}
      - VIDEO_FPS=${VIDEO_FPS:-30}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://ollama:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      - TTS_VOICE=${TTS_VOICE:-en}
    ports:
      - "${APP_PORT:-5000}:5000"
    depends_on:
      ollama:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -sSf http://127.0.0.1:5000/health > /dev/null"]
      interval: 10s
      timeout: 5s
      retries: 20
      start_period: 10s

volumes:
  ollama:

